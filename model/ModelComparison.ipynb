{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f5e1d88e",
      "metadata": {
        "id": "f5e1d88e"
      },
      "source": [
        "# 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d94a427f",
      "metadata": {
        "id": "d94a427f"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "\n",
        "from transformers import (\n",
        "  T5TokenizerFast as T5Tokenizer,\n",
        "  T5ForConditionalGeneration,\n",
        "  Seq2SeqTrainingArguments,\n",
        "  Seq2SeqTrainer,\n",
        "  DataCollatorForSeq2Seq\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import evaluate\n",
        "import gc\n",
        "import time\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "723c070f",
      "metadata": {
        "id": "723c070f"
      },
      "source": [
        "# 2. Import & Preprocessing Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7499b4c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Size: 720\n",
            "Validation Size: 90\n",
            "Test Size: 90\n"
          ]
        }
      ],
      "source": [
        "TOTAL_SAMPLES = 300\n",
        "MAX_INPUT_LENGTH = 512\n",
        "VAL_SIZE = 0.1\n",
        "TEST_SIZE = 0.1\n",
        "\n",
        "def clean_text(text):\n",
        "  if not text:\n",
        "    return \"\"\n",
        "  text = re.sub(r'\\s+([.,!?%:])', r'\\1', text)\n",
        "  return \" \".join(text.split())\n",
        "\n",
        "def filter_and_process(dataset, text_key, summary_key, style_name):\n",
        "  def process_example(example):\n",
        "    t_clean = clean_text(example[text_key])\n",
        "    s_clean = clean_text(example[summary_key])\n",
        "    \n",
        "    if style_name == \"Detailed\":\n",
        "      s_clean = clean_text(example[summary_key].lstrip('-–—').strip())\n",
        "      \n",
        "    return {\n",
        "      'text': t_clean,\n",
        "      'summary': s_clean,\n",
        "      'prompt': f\"Summarize {style_name}: {t_clean}\",\n",
        "      'word_count': len(t_clean.split())\n",
        "    }\n",
        "\n",
        "  processed_ds = dataset.map(process_example, remove_columns=dataset.column_names)\n",
        "  filtered_ds = processed_ds.filter(lambda x: 0 < x['word_count'] <= MAX_INPUT_LENGTH)\n",
        "  \n",
        "  return filtered_ds.select(range(min(TOTAL_SAMPLES, len(filtered_ds))))\n",
        "\n",
        "xsum_raw = load_dataset('xsum', trust_remote_code=True, split='train')\n",
        "cnn_raw = load_dataset('cnn_dailymail', '3.0.0', split='train')\n",
        "multi_raw = load_dataset('multi_news', trust_remote_code=True, split='train')\n",
        "\n",
        "harsh_ds = filter_and_process(xsum_raw, 'document', 'summary', 'Harsh')\n",
        "balanced_ds = filter_and_process(cnn_raw, 'article', 'highlights', 'Balanced')\n",
        "detailed_ds = filter_and_process(multi_raw, 'document', 'summary', 'Detailed')\n",
        "\n",
        "dataset = concatenate_datasets([harsh_ds, balanced_ds, detailed_ds])\n",
        "\n",
        "train_temp_split = dataset.train_test_split(test_size=TEST_SIZE + VAL_SIZE, shuffle=True, seed=42)\n",
        "train_ds = train_temp_split['train']\n",
        "temp_ds = train_temp_split['test']\n",
        "\n",
        "val_test_split = temp_ds.train_test_split(test_size=TEST_SIZE / (TEST_SIZE + VAL_SIZE), shuffle=True, seed=42)\n",
        "val_ds = val_test_split['train']\n",
        "test_ds = val_test_split['test']\n",
        "\n",
        "print(f\"Train Size: {len(train_ds)}\")\n",
        "print(f\"Validation Size: {len(val_ds)}\")\n",
        "print(f\"Test Size: {len(test_ds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f48fd9",
      "metadata": {
        "id": "48f48fd9"
      },
      "source": [
        "# 3. Configurations & Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0feff0d9",
      "metadata": {
        "id": "0feff0d9"
      },
      "outputs": [],
      "source": [
        "MODEL_LIST = [\n",
        "  't5-small',\n",
        "  't5-base',\n",
        "  'google/flan-t5-small',\n",
        "  'google/flan-t5-base',\n",
        "]\n",
        "OUT_DIRECTORY = 'results'\n",
        "MAX_TARGET_LENGTH = 256\n",
        "BATCH_SIZE = 4\n",
        "MAX_EPOCHS = 3\n",
        "GRADIENT_ACCUMULATION_STEPS = 2\n",
        "LEARNING_RATE = 5e-4\n",
        "SEED = 42\n",
        "\n",
        "evaluation_results = []\n",
        "inference_results = []\n",
        "\n",
        "# Text Reference: https://www.nbcnews.com/tech/tech-news/openai-disney-sora-ai-videos-rcna248617\n",
        "text = '''\n",
        "  The Walt Disney Co. announced Thursday that it had reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator.\n",
        "  Disney will also make a $1 billion investment in OpenAI, the owner of ChatGPT. It said it will become a “major customer” of OpenAI, using its services to develop new products and experiences, including for its Disney+ streaming service.\n",
        "  “Under the agreement, Disney and OpenAI are affirming a shared commitment to the responsible use of AI that protects user safety and the rights of creators,” the companies said in a statement.\n",
        "  They did not disclose the terms of the deal, and both Disney CEO Bob Iger and OpenAI CEO Sam Altman declined to reveal any details Thursday morning during a joint interview on CNBC.\n",
        "  OpenAI, meanwhile, said it has committed to “implementing responsible measures to further address trust and safety, including age-appropriate policies,” but did not provide additional details about what that would entail.\n",
        "  The issue of how AI chatbots engage with users under 18 is the subject of a national conversation and several lawsuits.\n",
        "  Disney said characters that are part of the deal include: Mickey Mouse, Minnie Mouse, Lilo, Stitch, Ariel, Belle, Beast, Cinderella, Baymax, Simba and Mufasa, as well as characters from the worlds of “Encanto,” “Frozen,” “Inside Out,” “Moana,” “Monsters Inc.,” “Toy Story,” “Up” and “Zootopia.”\n",
        "  On CNBC, Iger described the deal broadly as \"kind of a way\" for Disney to get into AI.\n",
        "  The deal is notable in part because Disney is famously protective of its sprawling portfolio of intellectual property, from the animated shorts of the 1920s to modern superhero and fantasy franchises.\n",
        "  Altman said, \"We hear so much from users about how much they love Disney,\" adding that he expects Sora users to respond \"very well\" to the inclusion of Disney characters.\n",
        "  The companies do not yet have a launch date yet, however, Altman said. \"We'll try to get it in there as soon as we can.\"\n",
        "  The company's statement had mentioned \"early 2026\" as a potential launch date.\n",
        "  Iger said in a statement, “Bringing together Disney’s iconic stories and characters with OpenAI’s groundbreaking technology puts imagination and creativity directly into the hands of Disney fans in ways we’ve never seen before, giving them richer and more personal ways to connect with the Disney characters and stories they love.\"\n",
        "  Media companies are wrestling with how to secure the value of their intellectual property while not being left behind by what many see as a transformative technology with few legal guardrails yet.\n",
        "  With OpenAI, Disney would be creating a legitimate avenue through which a generative AI program could deploy its characters, rather than playing whack-a-mole with every AI company, as Disney has done with other kinds of media in the past.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9020a510",
      "metadata": {
        "id": "9020a510"
      },
      "outputs": [],
      "source": [
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c5d5c50",
      "metadata": {
        "id": "7c5d5c50"
      },
      "source": [
        "# 4. Model Initialization & Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "67e6c758",
      "metadata": {
        "id": "67e6c758"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "  model_inputs = tokenizer(\n",
        "    examples[\"prompt\"],\n",
        "    max_length=MAX_INPUT_LENGTH,\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "  )\n",
        "  labels = tokenizer(\n",
        "    text_target=examples[\"summary\"],\n",
        "    max_length=MAX_TARGET_LENGTH,\n",
        "    truncation=True,\n",
        "    padding=\"max_length\"\n",
        "  )\n",
        "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "  return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6f900890",
      "metadata": {
        "id": "6f900890"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "  predictions, labels = eval_pred\n",
        "  predictions = np.clip(predictions, 0, tokenizer.vocab_size - 1)\n",
        "\n",
        "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "  result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "  return {k: round(v, 4) for k, v in result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NzHYTQvq5hP2",
      "metadata": {
        "id": "NzHYTQvq5hP2"
      },
      "outputs": [],
      "source": [
        "def generate_summary(text, style, model, tokenizer):\n",
        "  model.eval()\n",
        "  input_text = f\"Summarize {style}: {text}\"\n",
        "  input_words = len(text.split())\n",
        "\n",
        "  inputs = tokenizer(\n",
        "    input_text,\n",
        "    max_length=512,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        "  ).to(device)\n",
        "\n",
        "  if style == 'Harsh':\n",
        "    max_len = int(input_words * 0.35)\n",
        "    min_len = 5\n",
        "    rep_penalty = 2.5\n",
        "    length_penalty = 1.5\n",
        "    beam_size = 4\n",
        "    max_cap = 120\n",
        "  elif style == 'Balanced':\n",
        "    max_len = int(input_words * 0.50)\n",
        "    min_len = 20\n",
        "    rep_penalty = 1.5\n",
        "    length_penalty = 1.2\n",
        "    beam_size = 4\n",
        "    max_cap = 180\n",
        "  else:\n",
        "    max_len = int(input_words * 0.70)\n",
        "    min_len = 50\n",
        "    rep_penalty = 1.2\n",
        "    length_penalty = 0.8\n",
        "    beam_size = 4\n",
        "    max_cap = 256\n",
        "\n",
        "  max_len = min(max_len, max_cap)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "      input_ids=inputs['input_ids'],\n",
        "      attention_mask=inputs['attention_mask'],\n",
        "      max_length=max_len,\n",
        "      min_length=min_len,\n",
        "      num_beams=beam_size,\n",
        "      length_penalty=length_penalty,\n",
        "      repetition_penalty=rep_penalty,\n",
        "      no_repeat_ngram_size=3,\n",
        "      early_stopping=True\n",
        "    )\n",
        "\n",
        "  return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f679bb8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "f679bb8f",
        "outputId": "7909eb67-8757-4682-fb53-c30488604d0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training Model: t5-small ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 03:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.634500</td>\n",
              "      <td>0.951245</td>\n",
              "      <td>0.019800</td>\n",
              "      <td>0.012200</td>\n",
              "      <td>0.015700</td>\n",
              "      <td>0.015000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.268200</td>\n",
              "      <td>0.899299</td>\n",
              "      <td>0.025400</td>\n",
              "      <td>0.013300</td>\n",
              "      <td>0.019400</td>\n",
              "      <td>0.019000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training Model: t5-base ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 08:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.838000</td>\n",
              "      <td>0.784637</td>\n",
              "      <td>0.123000</td>\n",
              "      <td>0.055700</td>\n",
              "      <td>0.100500</td>\n",
              "      <td>0.099500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.062700</td>\n",
              "      <td>0.737808</td>\n",
              "      <td>0.163100</td>\n",
              "      <td>0.064300</td>\n",
              "      <td>0.114100</td>\n",
              "      <td>0.112500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training Model: google/flan-t5-small ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 03:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>10.004900</td>\n",
              "      <td>3.505064</td>\n",
              "      <td>0.268500</td>\n",
              "      <td>0.099100</td>\n",
              "      <td>0.192500</td>\n",
              "      <td>0.191600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.210500</td>\n",
              "      <td>2.574180</td>\n",
              "      <td>0.293800</td>\n",
              "      <td>0.113800</td>\n",
              "      <td>0.222300</td>\n",
              "      <td>0.220800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training Model: google/flan-t5-base ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 9:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>8.212400</td>\n",
              "      <td>0.722503</td>\n",
              "      <td>0.279600</td>\n",
              "      <td>0.106900</td>\n",
              "      <td>0.198800</td>\n",
              "      <td>0.198200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.991500</td>\n",
              "      <td>0.652271</td>\n",
              "      <td>0.347100</td>\n",
              "      <td>0.137600</td>\n",
              "      <td>0.247100</td>\n",
              "      <td>0.247500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for model_name in MODEL_LIST:\n",
        "  print(f\"=== Training Model: {model_name} ===\")\n",
        "\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "  tokenized_train = train_ds.map(preprocess_function, batched=True)\n",
        "  tokenized_valid = val_ds.map(preprocess_function, batched=True)\n",
        "  tokenized_test = test_ds.map(preprocess_function, batched=True)\n",
        "\n",
        "  model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "  lora_config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\"q\", \"k\", \"v\", \"o\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_2_SEQ_LM\"\n",
        "  )\n",
        "  model = get_peft_model(model, lora_config)\n",
        "  \n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.to(device)\n",
        "\n",
        "  training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=OUT_DIRECTORY,\n",
        "\n",
        "    num_train_epochs=MAX_EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.05,\n",
        "\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"no\",\n",
        "\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=MAX_TARGET_LENGTH,\n",
        "    report_to=\"none\"\n",
        "  )\n",
        "\n",
        "  trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_valid,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
        "    compute_metrics=compute_metrics\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "\n",
        "  val_metrics = trainer.evaluate()\n",
        "  test_metrics = trainer.evaluate(eval_dataset=tokenized_test, metric_key_prefix=\"test\")\n",
        "  evaluation_results.append({\n",
        "    \"Model\": model_name,\n",
        "\n",
        "    \"Val ROUGE-1\": val_metrics.get(\"eval_rouge1\"),\n",
        "    \"Val ROUGE-2\": val_metrics.get(\"eval_rouge2\"),\n",
        "    \"Val ROUGE-L\": val_metrics.get(\"eval_rougeL\"),\n",
        "    \"Val ROUGE-L Summary\": val_metrics.get(\"eval_rougeLsum\"),\n",
        "\n",
        "    \"Test ROUGE-1\": test_metrics.get(\"test_rouge1\"),\n",
        "    \"Test ROUGE-2\": test_metrics.get(\"test_rouge2\"),\n",
        "    \"Test ROUGE-L\": test_metrics.get(\"test_rougeL\"),\n",
        "    \"Test ROUGE-L Summary\": test_metrics.get(\"test_rougeLsum\")\n",
        "  })\n",
        "\n",
        "  styles = [\"Harsh\", \"Balanced\", \"Detailed\"]\n",
        "  model_outputs = {\"Model\": model_name}\n",
        "\n",
        "  for style in styles:\n",
        "    summary = generate_summary(text, style, model, tokenizer)\n",
        "    model_outputs[style] = summary\n",
        "\n",
        "  inference_results.append(model_outputs)\n",
        "\n",
        "  del model\n",
        "  del trainer\n",
        "  del tokenizer\n",
        "  del tokenized_train\n",
        "  del tokenized_valid\n",
        "  del tokenized_test\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6f08531",
      "metadata": {
        "id": "c6f08531"
      },
      "source": [
        "# 5. Model Evaluation Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fcc8aad8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "fcc8aad8",
        "outputId": "49c44a32-5395-4903-e56e-1d1c9d5b3404"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Val ROUGE-1</th>\n",
              "      <th>Val ROUGE-2</th>\n",
              "      <th>Val ROUGE-L</th>\n",
              "      <th>Val ROUGE-L Summary</th>\n",
              "      <th>Test ROUGE-1</th>\n",
              "      <th>Test ROUGE-2</th>\n",
              "      <th>Test ROUGE-L</th>\n",
              "      <th>Test ROUGE-L Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>t5-small</td>\n",
              "      <td>0.0330</td>\n",
              "      <td>0.0153</td>\n",
              "      <td>0.0252</td>\n",
              "      <td>0.0249</td>\n",
              "      <td>0.0767</td>\n",
              "      <td>0.0289</td>\n",
              "      <td>0.0558</td>\n",
              "      <td>0.0556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>t5-base</td>\n",
              "      <td>0.2202</td>\n",
              "      <td>0.0838</td>\n",
              "      <td>0.1534</td>\n",
              "      <td>0.1525</td>\n",
              "      <td>0.2240</td>\n",
              "      <td>0.0951</td>\n",
              "      <td>0.1550</td>\n",
              "      <td>0.1563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>google/flan-t5-small</td>\n",
              "      <td>0.2996</td>\n",
              "      <td>0.1106</td>\n",
              "      <td>0.2240</td>\n",
              "      <td>0.2220</td>\n",
              "      <td>0.3054</td>\n",
              "      <td>0.1181</td>\n",
              "      <td>0.2213</td>\n",
              "      <td>0.2220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>google/flan-t5-base</td>\n",
              "      <td>0.3697</td>\n",
              "      <td>0.1549</td>\n",
              "      <td>0.2680</td>\n",
              "      <td>0.2670</td>\n",
              "      <td>0.3565</td>\n",
              "      <td>0.1484</td>\n",
              "      <td>0.2629</td>\n",
              "      <td>0.2623</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Model  Val ROUGE-1  Val ROUGE-2  Val ROUGE-L  \\\n",
              "0              t5-small       0.0330       0.0153       0.0252   \n",
              "1               t5-base       0.2202       0.0838       0.1534   \n",
              "2  google/flan-t5-small       0.2996       0.1106       0.2240   \n",
              "3   google/flan-t5-base       0.3697       0.1549       0.2680   \n",
              "\n",
              "   Val ROUGE-L Summary  Test ROUGE-1  Test ROUGE-2  Test ROUGE-L  \\\n",
              "0               0.0249        0.0767        0.0289        0.0558   \n",
              "1               0.1525        0.2240        0.0951        0.1550   \n",
              "2               0.2220        0.3054        0.1181        0.2213   \n",
              "3               0.2670        0.3565        0.1484        0.2629   \n",
              "\n",
              "   Test ROUGE-L Summary  \n",
              "0                0.0556  \n",
              "1                0.1563  \n",
              "2                0.2220  \n",
              "3                0.2623  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rouge_df = pd.DataFrame(evaluation_results)\n",
        "display(rouge_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4134fd5a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Model: t5-small ===\n",
            "Harsh (Words: 53):\n",
            "The Walt Disney Co. announced Thursday that it had reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator. It said it will become a “major customer” of OpenAI, using its services to develop new products and experiences, including for its Disney+ streaming service.\n",
            "\n",
            "Balanced (Words: 59):\n",
            "The Walt Disney Co. announced Thursday that it had reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator. The deal is notable in part because Disney is famously protective of its sprawling portfolio of intellectual property, from the animated shorts of the 1920s to modern superhero and fantasy franchises.\n",
            "\n",
            "Detailed (Words: 59):\n",
            "The Walt Disney Co. announced Thursday that it had reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator. The deal is notable in part because Disney is famously protective of its sprawling portfolio of intellectual property, from the animated shorts of the 1920s to modern superhero and fantasy franchises.\n",
            "\n",
            "=== Model: t5-base ===\n",
            "Harsh (Words: 53):\n",
            "Disney has reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator. It will also make a $1 billion investment in OpenAI, the owner of ChatGPT. The deal is notable in part because Disney is famously protective of its sprawling portfolio of intellectual property.\n",
            "\n",
            "Balanced (Words: 38):\n",
            "The Walt Disney Co. has reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator. Disney will also make a $1 billion investment in OpenAI, the owner of ChatGPT.\n",
            "\n",
            "Detailed (Words: 45):\n",
            "Disney has reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator. Disney will also make a $1 billion investment in OpenAI, the owner of ChatGPT. Disney said it will become a \"major customer\" of OpenAI.\n",
            "\n",
            "=== Model: google/flan-t5-small ===\n",
            "Harsh (Words: 24):\n",
            "The Walt Disney Co. has reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator.\n",
            "\n",
            "Balanced (Words: 21):\n",
            "Disney has reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator.\n",
            "\n",
            "Detailed (Words: 42):\n",
            "The Walt Disney Co. announced Thursday that it had reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator. Disney will also make a $1 billion investment in OpenAI, the owner of ChatGPT.\n",
            "\n",
            "=== Model: google/flan-t5-base ===\n",
            "Harsh (Words: 38):\n",
            "The Walt Disney Co. has reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator. It will also make a $1 billion investment in OpenAI, the owner of ChatGPT.\n",
            "\n",
            "Balanced (Words: 50):\n",
            "The Walt Disney Co. has reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator. It said it will become a \"major customer\" of OpenAI, using its services to develop new products and experiences, including for its Disney+ streaming service.\n",
            "\n",
            "Detailed (Words: 93):\n",
            "The Walt Disney Co. has reached a three-year agreement with OpenAI to bring its popular characters to the company's Sora artificial intelligence video generator. It said it will become a \"major customer\" of OpenAI, using its services to develop new products and experiences, including for its Disney+ streaming service. Disney said characters that are part of the deal include: Mickey Mouse, Minnie Mouse, Lilo, Stitch, Ariel, Belle, Beast, Cinderella, Baymax, Simba and Mufasa, as well as characters from the worlds of \"Encanto,\" \"Frozen,\" \"Inside Out,\" \"Moana,\" \"Monsters Inc.,\" \"Toy Story,\" \"Up\" and \"Zootopia.\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "style_df = pd.DataFrame(inference_results)\n",
        "style_df.set_index('Model', inplace=True)\n",
        "\n",
        "for _, row in style_df.iterrows():\n",
        "  print(f\"=== Model: {row.name} ===\")\n",
        "  for style in [\"Harsh\", \"Balanced\", \"Detailed\"]:\n",
        "    summary = row[style]\n",
        "    word_count = len(summary.split())\n",
        "    print(f\"{style} (Words: {word_count}):\")\n",
        "    print(summary)\n",
        "    print(\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
